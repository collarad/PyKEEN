{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding Projector.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/collarad/PyKEEN/blob/master/notebooks/visualization/Embedding_Projector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPcnY2A2QLnp",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Vectors and Metadata to tsv\n",
        "In this Notebook we are going to export PyKeen created embeddings to tsv files expected by the [Embedding Projector](https://projector.tensorflow.org/) tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUa1k7GFQund",
        "colab_type": "text"
      },
      "source": [
        "# Initial Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8EUC74E47Vf",
        "colab_type": "text"
      },
      "source": [
        "## Clonning Repository\n",
        "Cloning the git repository containing PyKeen embeddings. In this example we are going to clone embeddings create for the Industry 4.0 Standards Landscape Knowledge Graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHrBTcJUOWrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/i40-Tools/I40KG-Embeddings.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMCn5RQV4O6A",
        "colab_type": "text"
      },
      "source": [
        "## Installing Libraries\n",
        "\n",
        "Install and import the [rdflib](https://github.com/RDFLib/rdflib) library, to execute SPARQL queries to limit the scope of the embeddings we would like to display."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuasBvcIUv6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install rdflib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjlkvlMBU-FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from rdflib import Graph\n",
        "import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j69IqvH07NNe",
        "colab_type": "text"
      },
      "source": [
        "## Defining Main Variables\n",
        "We use two main variables in the rest of the notebook:\n",
        "\n",
        "1.   **kg_path**: Correspont to the path of the knowledge graph, i.e., ***file-name.nt.*** Do not forget that you have to add /content/ folder at the begining of the path to find in the clonned repo in Colab.\n",
        "2.   **emb_path**: Correspont to the path containing the embedding output after PyKeen training phase, i.e., ***file-name.json***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u4HRUH2VYiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kg_path = \"/content/I40KG-Embeddings/embeddings/sto/sto-enriched.nt\"\n",
        "emb_path = \"/content/I40KG-Embeddings/embeddings/training_set_relatedTo/TransH/entities_to_embeddings.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUAASSQS8nZT",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Vecs and Meta TSV Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F709UQHl8vV3",
        "colab_type": "text"
      },
      "source": [
        "## Creating labels and tokens\n",
        "First, we will run a SPARQL query to select the entities embeddings we would like to export for visualization on Embedding Projector. We create at the same time labels and tokens to be exported as TSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWu4AVnYWE-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = Graph()\n",
        "g.parse(kg_path, format=\"nt\")\n",
        "len(g) # prints 2\n",
        "\n",
        "#query to get all the standards from the sto.nt file\n",
        "qres = g.query(\"\"\"\n",
        "        PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
        "        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "        PREFIX sto: <https://w3id.org/i40/sto#>\n",
        "        \n",
        "        select ?s where {\n",
        "           ?s rdf:type sto:Standard .\n",
        "         } limit 1000 \n",
        "        \"\"\")\n",
        "\n",
        "labels = []\n",
        "tokens = []\n",
        "\n",
        "#to get the corresponding embeddings of the frameworks/standards from the json file \n",
        "with open(emb_path,'rb') as f:\n",
        "    array = json.load(f)\n",
        "for row in qres:\n",
        "    for key,value in array.items():\n",
        "        if key == \"%s\" % row:\n",
        "            labels.append(key.replace('https://w3id.org/i40/', '')) # Just to clean the namespace for better visualization in embedding projector\n",
        "            tokens.append(array[key])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiUbj_Iti14N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(labels))\n",
        "print(len(tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inmGQ-gb_fYm",
        "colab_type": "text"
      },
      "source": [
        "## Saving vecs and meta TSV files\n",
        "Now, based on the labels and tokens we create the TSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weqNNncljdRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "standards_size = len(labels)\n",
        "\n",
        "for standard_num in range(1, standards_size):\n",
        "  out_m.write(labels[standard_num] + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in tokens[standard_num]]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dUdg_-r_ucy",
        "colab_type": "text"
      },
      "source": [
        "## Downloading Files\n",
        "If you are working in colab, the following piece of code is required to download vecs and meta TSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqkUbrlekR1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ8_oh9iBR6Q",
        "colab_type": "text"
      },
      "source": [
        "# Uploading files in Embedding Projector\n",
        "Now you are ready to visualize the embeddings using [Embedding Projector](https://projector.tensorflow.org/). We have created a video showing how to upload the resulting data from this notebook into Embedding Projector: [video](https://youtu.be/cNhX2XtiWQM).\n"
      ]
    }
  ]
}